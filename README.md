# LLM-Acceleration
Comprehensive Acceleration of Llama-3.2-3B-Instruct with GPTQ-Quantization, VLLM, KV-Cache Quantization, Speculative Decoding, and Flash Attention.
